import math
import os
import shutil
import pandas as pd
import numpy as np
from fractions import Fraction

from matplotlib import pyplot as plt
import seaborn as sns
import Label_Enhanced_UsingNumba
from sklearn.preprocessing import MinMaxScaler


class FeatureSelectionAlgorithm:
    def __init__(self, file_path=None):
        self.file_path = file_path  # è¯»å–çš„æ–‡ä»¶è·¯å¾„
        self.output_dir = None  # å¢å¼ºç»“æœå¯è§†åŒ–è·¯å¾„
        self.data = None
        self.result = None  # å½’ä¸€ç»“æœ
        self.labellist = None  # å¢å¼ºç»“æœ
        self.target_column = None  # ç›®æ ‡åˆ—
        self.label_length = None  # ç›®æ ‡åˆ—é•¿åº¦

    def get_columns(self):
        return list(self.data.columns)

    def exchange(self, response):
        columns = self.get_columns()
        # é‡æ–°ç»„åˆåˆ—åï¼Œå°†é€‰æ‹©çš„åˆ—æ”¾åˆ°æœ€å
        new_columns = [col for col in columns if col not in response] + response

        # æ ¹æ®æ–°çš„åˆ—é¡ºåºåˆ›å»ºæ–°çš„ DataFrame
        self.data = self.data[new_columns].copy()

    # åŠ è½½æ–‡ä»¶
    def loadfile(self):
        if self.file_path:
            if self.file_path.endswith('.csv'):
                self.data = pd.read_csv(self.file_path)
            elif self.file_path.endswith('.xlsx'):
                self.data = pd.read_excel(self.file_path)
            else:
                raise FileNotFoundError('File type not supported')
        else:
            raise FileNotFoundError('File path not specified')

    # å½’ä¸€åŒ– å°†æ¯ä¸ªç‰¹å¾ä¸‹çš„æ•°æ®å½’ä¸€åŒ–{0,1}
    def normalization(self):
        minmax = MinMaxScaler(feature_range=(0, 1))
        data = np.array(self.data, float)
        self.result = minmax.fit_transform(data)

    # è·å–æ•°æ®é›†ä¸­çš„é‚»åŸŸé˜ˆå€¼
    def GetNeigborhoodThreshold(self, ConditionalFeatues, Omega):
        """
        è·å–æ•°æ®é›†çš„é¢†åŸŸé˜ˆå€¼
        :param ConditionalFeatues:
        :param Omega:
        :return:
        """
        Temp = 0.0
        Length = ConditionalFeatues.__len__()
        for f in ConditionalFeatues:
            Column_Vector = self.result[:, f]
            T = np.std(Column_Vector) / Omega
            Temp += T
        Result = float((Temp / Length) / Omega)
        return Result

    # æ„å»ºæ ‡è®°é›†åˆçš„0~1å¯¹åº”å®ä¾‹é›†åˆ
    def ConstructLiInstanceList(self, LabelList, weight_factor=0.1):
        """
        åŸºäºæ ‡è®°å¢å¼ºï¼Œç”Ÿæˆ [0,1] å°æ•°èŒƒå›´çš„æ ‡è®°é›†åˆå¯¹åº”å®ä¾‹é›†åˆã€‚
        :param LabelList: è¦å¤„ç†çš„æ ‡è®°é›†åˆ
        :param weight_factor: æ§åˆ¶æ ‡è®°å¢å¼ºçš„å°æ•°èŒƒå›´æƒé‡
        :return: åŒ…å«å¢å¼ºæ ‡è®°çš„å°æ•°ç»“æœåˆ—è¡¨
        1. è½¯æ ‡è®°ï¼ˆSoft Labelingï¼‰çš„ç†è®ºæ”¯æŒ
        ä¼ ç»Ÿçš„äºŒåˆ†ç±»æ ‡è®°ï¼ˆ0 å’Œ 1ï¼‰è¢«ç§°ä¸ºç¡¬æ ‡è®°ï¼ˆHard Labelingï¼‰ï¼Œä½†åœ¨è®¸å¤šæœºå™¨å­¦ä¹ ä»»åŠ¡ä¸­ï¼Œç‰¹åˆ«æ˜¯åœ¨æ·±åº¦å­¦ä¹ é¢†åŸŸï¼Œ**è½¯æ ‡è®°ï¼ˆSoft Labelingï¼‰**è¢«è¯æ˜å¯ä»¥æé«˜æ¨¡å‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›ã€‚

        è½¯æ ‡è®°çš„å…¬å¼ï¼šğ‘¦â€²=y+Ïµ
        å…¶ä¸­ï¼šğ‘¦æ˜¯åŸå§‹çš„ç¦»æ•£æ ‡è®°ï¼ˆ0 æˆ– 1ï¼‰ã€‚
        ğœ–æ˜¯ä¸€ä¸ªéšæœºå™ªå£°æˆ–åŠ æƒåç§»é‡ï¼Œç”¨äºå¼•å…¥è¿ç»­æ€§ã€‚
        é€šè¿‡å°†æ ‡è®°å€¼ä»ç¦»æ•£å€¼è½¬åŒ–ä¸ºå¸¦æƒé‡çš„å°æ•°ï¼ˆå¦‚ 0.1 æˆ– 0.9ï¼‰ï¼Œå¯ä»¥æ›´å‡†ç¡®åœ°è¡¨ç¤ºæ•°æ®ç‚¹çš„å®é™…ç±»åˆ«åˆ†å¸ƒã€‚è¿™ç§æ–¹å¼åœ¨åŠç›‘ç£å­¦ä¹ å’Œå¯¹æŠ—è®­ç»ƒä¸­æœ‰è¾ƒå¹¿æ³›çš„åº”ç”¨ã€‚
        æ–‡çŒ®æ”¯æŒï¼š
        Hinton, G., et al. "Distilling the Knowledge in a Neural Network" (2015). æå‡ºä½¿ç”¨**æ¸©åº¦è½¯åŒ–ï¼ˆSoftmax with Temperatureï¼‰**çš„æ–¹å¼å°†åˆ†ç±»æ ‡è®°è½¬åŒ–ä¸ºè¿ç»­æ¦‚ç‡åˆ†å¸ƒã€‚
        """
        ResultList = []
        for Index in LabelList:
            T = []
            for Criterion in [0, 1]:
                Temp = [
                    (i, Criterion + weight_factor * (2 * (i % 2) - 1))  # å¢åŠ å°æ•°æƒé‡
                    for i, x in enumerate(self.result[:, Index])
                    if x == Criterion
                ]
                T.append(Temp)
            ResultList.append(T)
        # åˆ›å»º img æ–‡ä»¶å¤¹
        self.output_dir = os.path.join(os.path.dirname(os.path.abspath(os.path.dirname(__file__))),
                                       "static\\img\\%s"%self.file_path.split('.')[0].split('\\')[-1])
        if os.path.exists(self.output_dir):
            shutil.rmtree(self.output_dir)
        os.makedirs(self.output_dir, exist_ok=True)
        label_length = len(LabelList)
        for i in range(label_length):
            self.save_plot_to_local(ResultList, col_index=i, columns=self.get_columns(), output_dir=self.output_dir,
                                    label_length=len(LabelList))
        return ResultList

    def save_plot_to_local(self, ResultList, col_index, columns, output_dir, label_length):
        """
           ä» ResultList ä¸­æå–ç›®æ ‡åˆ—çš„å¢å¼ºå€¼ï¼Œå¹¶ç»˜åˆ¶ç›´æ–¹å›¾ã€‚

           :param ResultList: æ ‡è®°å¢å¼ºç»“æœåˆ—è¡¨
           :param col_index: è¦ç»˜åˆ¶çš„ç›®æ ‡åˆ—ç´¢å¼•
           """
        # æå–ç›®æ ‡åˆ—çš„å¢å¼ºå€¼
        target_data = []
        column_data = ResultList[col_index]  # è·å–æŒ‡å®šç›®æ ‡åˆ—çš„ Criterion åˆ—è¡¨
        for criterion_data in column_data:  # éå† Criterion 0 å’Œ 1
            target_data.extend([val[1] for val in criterion_data])  # æå–å¢å¼ºå€¼

        # ç»˜åˆ¶ç›´æ–¹å›¾
        plt.figure(figsize=(8, 5))
        sns.histplot(target_data, bins=30, kde=True, color="skyblue")
        plt.title(f"Histogram of Enhanced Values {columns[len(columns)-label_length+col_index]}")
        plt.xlabel("Enhanced Values")
        plt.ylabel("Frequency")
        # ä¿å­˜åˆ° img æ–‡ä»¶å¤¹
        output_file = os.path.join(output_dir, f"histogram_column_{columns[len(columns)-label_length+col_index]}.png")
        plt.savefig(output_file)
        plt.close()
        plt.show()

    # æ„å»ºæ¯ä¸ªç‰¹å¾ä¸‹çš„æ¯ä¸ªå®ä¾‹çš„é‚»åŸŸé›†åˆçš„çŸ©é˜µ
    def ConstructNeighborhoodMatrix_Feature(self, ConditionalFeatures, Threshold):
        Features_Length = ConditionalFeatures.__len__()
        Data_Length = self.result.shape[0]
        Result_Matrix = np.zeros((Features_Length, Data_Length), dtype=list)
        # TODO è¿™é‡Œéœ€è¦æ”¹å‚æ•°
        for f in ConditionalFeatures[0:1000]:
            for Xi in range(Data_Length):
                T = []
                for Xj in range(Data_Length):
                    Vector1 = self.result[Xi, f]
                    Vector2 = self.result[Xj, f]
                    Distance = np.linalg.norm(Vector1 - Vector2)
                    if Distance <= Threshold:
                        T.append(Xj)
                Result_Matrix[f][Xi] = T  # Tä¸ºXiåœ¨fä¸‹çš„é¢†åŸŸçŸ©é˜µ
        return Result_Matrix  # è¿”å›çš„æ˜¯æ‰€æœ‰æ ·ä¾‹åœ¨æ‰€æœ‰ç‰¹å¾ä¸‹çš„é¢†åŸŸæ ·ä¾‹æ‰€æ„æˆçš„çŸ©é˜µ


    # è·å–æ ‡è®°åˆ†å¸ƒä¸‹çš„æ ‡è®°æƒé‡
    def Get_Label_Weight(self, LabelLength, Omega):
        """
        è·å–æ ‡è®°åˆ†å¸ƒï¼šè°ƒç”¨ Label_Enhanced_UsingNumba.ReturnLabelDistribution æ–¹æ³•ï¼Œä¼ å…¥ç»“æœé›† self.resultã€å‚æ•° Omega å’Œæ ‡è®°é•¿åº¦ LabelLengthã€‚è¯¥æ–¹æ³•è¿”å›æ ‡è®°åˆ†å¸ƒç»“æœ Label_Distribution_Resultã€‚

        è½¬æ¢ä¸º NumPy æ•°ç»„ï¼šå°† Label_Distribution_Result è½¬æ¢ä¸º NumPy æ•°ç»„ Maritixï¼Œä»¥ä¾¿äºåç»­çš„æ•°ç»„æ“ä½œã€‚

        åˆå§‹åŒ–æƒé‡ç»“æœåˆ—è¡¨ï¼šåˆ›å»ºä¸€ä¸ªç©ºçš„åˆ—è¡¨ Weight_Result ç”¨äºå­˜å‚¨æ¯ä¸ªæ ‡è®°çš„æƒé‡ã€‚

        å¾ªç¯è®¡ç®—æ¯ä¸ªæ ‡è®°çš„æƒé‡ï¼š

        å¯¹äºæ¯ä¸ªæ ‡è®°ç´¢å¼• indexï¼ˆèŒƒå›´ä» 0 åˆ° LabelLength-1ï¼‰ï¼Œæå–å¯¹åº”çš„åˆ†å¸ƒå€¼ Tã€‚
        åˆå§‹åŒ– Total_Sum ä¸º 0ï¼Œç”¨äºç´¯åŠ åˆ†æ•°ã€‚
        éå† T ä¸­çš„æ¯ä¸ªå€¼ iï¼Œå°†å…¶è½¬æ¢ä¸ºåˆ†æ•°ç±»å‹ Fraction(i)ï¼Œå¹¶ç´¯åŠ åˆ° Total_Sum ä¸­ã€‚
        è®¡ç®—æƒé‡ï¼šé€šè¿‡ Fraction(Total_Sum, self.result.shape[0]) è®¡ç®—è¯¥æ ‡è®°çš„æƒé‡ Tempï¼Œå³è¯¥æ ‡è®°åˆ†å¸ƒæ€»å’Œä¸ç»“æœé›†å¤§å°çš„æ¯”å€¼ã€‚

        ä¿å­˜æƒé‡ï¼šå°†è®¡ç®—å¾—åˆ°çš„æƒé‡ Temp æ·»åŠ åˆ° Weight_Result åˆ—è¡¨ä¸­ã€‚

        è¿”å›ç»“æœï¼šæœ€ç»ˆè¿”å› Weight_Result åˆ—è¡¨ï¼ŒåŒ…å«æ¯ä¸ªæ ‡è®°çš„æƒé‡ã€‚
        """
        Label_Distribution_Result, _ = Label_Enhanced_UsingNumba.ReturnLabelDistribution(self.result, Omega,
                                                                                         LabelLength)
        Maritix = np.array(Label_Distribution_Result)
        Weight_Result = []
        for index in range(LabelLength):
            T = Maritix[:, index]
            Total_Sum = 0
            for i in T:
                Total_Sum += Fraction(i)
            Temp = Fraction(Total_Sum, self.result.shape[0])
            Weight_Result.append(Temp)
        return Weight_Result


    # è®¡ç®—å€™é€‰ç‰¹å¾ä¸å·²é€‰ç‰¹å¾é›†åˆçš„äº¤äº’æ€§
    def ComputeInteractiveBetween_fi_and_S(self, fi, Selected_S, LabelIndexList, RelevanceMatrix,
                                           RedundancyMatrix, NeighborhoodMatrix_Feature, Threshold):
        Mid = 0.0
        Label_Length = LabelIndexList.__len__()
        DataLength = self.result.shape[0]
        # TODO è¿™é‡Œéœ€è¦æ”¹å‚æ•°
        if fi > 1000:
            for Xi in range(DataLength):
                Neigborhood_fi_List = []
                Vector_1 = self.result[Xi][fi]
                for Xj in range(DataLength):
                    Vector_2 = self.result[Xj][fi]
                    Distance = np.linalg.norm(Vector_1 - Vector_2)
                    if Distance <= Threshold:
                        Neigborhood_fi_List.append(Xj)
                T = Neigborhood_fi_List.__len__()
                Temp = float(T / DataLength)
                Mid += math.log2(Temp)
            Entropy_fi = -1 / DataLength * Mid
        else:
            for Xi in range(DataLength):
                Neigborhood_fi_List = NeighborhoodMatrix_Feature[fi][Xi]
                T = Neigborhood_fi_List.__len__()
                Temp = float(T / DataLength)
                Mid += math.log2(Temp)
            Entropy_fi = -1 / DataLength * Mid
        Result = 0.0
        for s in Selected_S:
            Value_1 = 0.0
            if RedundancyMatrix[fi][s] == 0:
                for Lj in range(Label_Length):
                    Value_1 += (1 - (RelevanceMatrix[fi][Lj] / Entropy_fi)) * RedundancyMatrix[s][fi]
            else:
                for Lj in range(Label_Length):
                    Value_1 += (1 - (RelevanceMatrix[fi][Lj] / Entropy_fi)) * RedundancyMatrix[fi][s]
            Result += Value_1
        # return ResultComputeInteractiveBetween_fi_and_candidate
        return Result


    # æ„å»ºç‰¹å¾ä¾èµ–åº¦çŸ©é˜µ
    def ConstructRelevanceMatrix(self, CondintionalFeatures, LabelList, Weight_List,
                                 NeighborhoodMatrix_Feature, LiisLabelList, Threshold):
        """
        :param CondintionalFeatures:
        :param LabelList:
        :param Weight_List:
        :param NeighborhoodMatrix_Feature:
        :param LiisLabelList: ?
        :param Threshold:
        :return:
        """
        LabelLength_LabelList = LabelList.__len__()
        Relevance_Matrix = np.zeros((CondintionalFeatures.__len__(), LabelLength_LabelList), dtype=float)
        StarIndex = LabelList[0]  # å¼€å§‹ä¸ºæ ‡ç­¾åˆ—è¡¨ç´¢å¼•
        Total_Length = self.result.shape[0]
        # TODO è¿™é‡Œéœ€è¦æ”¹å‚æ•°
        for f in CondintionalFeatures:
            # print(f)
            if f > 1000:
                Column = -1
                for l in LabelList:
                    Column += 1
                    Weight_Index = l - StarIndex
                    Mid = 0.0
                    for Xi in range(Total_Length):
                        Vector_1 = self.result[Xi][f]
                        Neigborhood_f_List = []
                        for Xj in range(Total_Length):
                            Vector_2 = self.result[Xj][f]
                            Distance = np.linalg.norm(Vector_1 - Vector_2)
                            if Distance <= Threshold:
                                Neigborhood_f_List.append(Xj)
                        Neigborhood_li_List = LiisLabelList[Weight_Index][int(self.result[Xi][l])]
                        T = list(set(Neigborhood_f_List) & set(Neigborhood_li_List))
                        if T.__len__() == 0:
                            Temp = 1e-10
                        else:
                            Temp = float(
                                Neigborhood_f_List.__len__() * Neigborhood_li_List.__len__() / (
                                        Total_Length * T.__len__()))
                        Mid += math.log2(Temp)
                    Result = float((-1 / Total_Length) * Weight_List[Weight_Index]) * Mid
                    Relevance_Matrix[f, Column] = Result
            else:
                Column = -1
                for l in LabelList:
                    Column += 1
                    Weight_Index = l - StarIndex
                    Mid = 0.0
                    for Xi in range(Total_Length):
                        Neigborhood_f_List = NeighborhoodMatrix_Feature[f][Xi]
                        Neigborhood_li_List = LiisLabelList[Weight_Index][int(self.result[Xi][l])]
                        T = list(set(Neigborhood_f_List) & set(Neigborhood_li_List))
                        intersection_len = T.__len__()
                        if intersection_len == 0:
                            Temp = 1e-10  # é€‰æ‹©ä¸€ä¸ªå¾ˆå°çš„æ­£æ•°æ¥ä»£æ›¿
                        else:
                            Temp = float(Neigborhood_f_List.__len__() * Neigborhood_li_List.__len__() / (
                                    Total_Length * intersection_len))
                        Mid += math.log2(Temp)
                    Result = float((-1 / Total_Length) * Weight_List[Weight_Index]) * Mid
                    Relevance_Matrix[f, Column] = Result
        return Relevance_Matrix
        # """
        # ä¸ºä»€ä¹ˆå½“ç‰¹å¾å°äº1000æ—¶ï¼Œåœ¨è¯¥ç‰¹å¾ä¸‹çš„æ ·ä¾‹çš„é¢†åŸŸçŸ©é˜µï¼Œå¯èƒ½è·Ÿå­˜å‚¨æœ‰å…³
        # """


    # æ„å»ºç‰¹å¾å†—ä½™åº¦çŸ©é˜µ
    def ConstructRedundancyMatrix(self, ConditionalFeatures, NeighborhoodMatrix_Feature, Threshold):
        """
        :param ConditionalFeatures: æ¡ä»¶ç‰¹å¾
        :param NeighborhoodMatrix_Feature: åœ¨è¯¥ç‰¹å¾ä¸‹çš„é¢†åŸŸç‰¹å¾çŸ©é˜µ
        :param Threshold:
        :return:
        """
        Length_ConditionalFeatures = ConditionalFeatures.__len__()
        Redundancuy_Matrix = np.zeros((Length_ConditionalFeatures, Length_ConditionalFeatures), dtype=float)
        DataLength = self.result.shape[0]
        for fi in ConditionalFeatures:
            for fj in range(fi + 1, Length_ConditionalFeatures):
                # TODO è¿™é‡Œéœ€è¦æ”¹å‚æ•°
                if (fi > 1000) and (fj <= 1000):
                    Mid = 0.0
                    for Xi in range(DataLength):
                        Neigborhood_fi_List = []
                        Vector_1 = self.result[Xi][fi]
                        for Xj in range(DataLength):
                            Vector_2 = self.result[Xj][fi]
                            Distance = np.linalg.norm(Vector_1 - Vector_2)
                            if Distance <= Threshold:
                                Neigborhood_fi_List.append(Xj)
                        Neigborhood_fj_List = NeighborhoodMatrix_Feature[fj][Xi]
                        T = list(set(Neigborhood_fi_List) & set(Neigborhood_fj_List))
                        Temp = float(
                            Neigborhood_fi_List.__len__() * Neigborhood_fj_List.__len__() / (DataLength * T.__len__()))
                        Mid += math.log2(Temp)
                    Result = float((-1 / DataLength) * Mid)
                    Redundancuy_Matrix[fi, fj] = Result
                elif (fi <= 1000) and (fj > 1000):
                    Mid = 0.0
                    for Xi in range(DataLength):
                        Neigborhood_fj_List = []
                        Vector_1 = self.result[Xi][fj]
                        for Xj in range(DataLength):
                            Vector_2 = self.result[Xj][fj]
                            Distance = np.linalg.norm(Vector_1 - Vector_2)
                            if Distance <= Threshold:
                                Neigborhood_fj_List.append(Xj)
                        Neigborhood_fi_List = NeighborhoodMatrix_Feature[fi][Xi]
                        T = list(set(Neigborhood_fi_List) & set(Neigborhood_fj_List))
                        Temp = float(
                            Neigborhood_fi_List.__len__() * Neigborhood_fj_List.__len__() / (DataLength * T.__len__()))
                        Mid += math.log2(Temp)
                    Result = float((-1 / DataLength) * Mid)
                    Redundancuy_Matrix[fi, fj] = Result
                elif (fi <= 1000) and (fj <= 1000):
                    Mid = 0.0
                    for Xi in range(DataLength):
                        Neigborhood_fi_List = NeighborhoodMatrix_Feature[fi][Xi]
                        Neigborhood_fj_List = NeighborhoodMatrix_Feature[fj][Xi]
                        T = list(set(Neigborhood_fi_List) & set(Neigborhood_fj_List))
                        Temp = float(
                            Neigborhood_fi_List.__len__() * Neigborhood_fj_List.__len__() / (DataLength * T.__len__()))
                        Mid += math.log2(Temp)
                    Result = float((-1 / DataLength) * Mid)
                    Redundancuy_Matrix[fi, fj] = Result
                else:
                    Mid = 0.0
                    for Xi in range(DataLength):
                        Neigborhood_fi_List = []
                        Neigborhood_fj_List = []
                        Vector_fi_1 = self.result[Xi][fi]
                        Vector_fj_1 = self.result[Xi][fj]
                        for Xj in range(DataLength):
                            Vector_fi_2 = self.result[Xj][fi]
                            Vector_fj_2 = self.result[Xj][fj]
                            Distance1 = np.linalg.norm(Vector_fi_1 - Vector_fi_2)
                            Distance2 = np.linalg.norm(Vector_fj_1 - Vector_fj_2)
                            if Distance1 <= Threshold:
                                Neigborhood_fi_List.append(Xj)
                            if Distance2 <= Threshold:
                                Neigborhood_fj_List.append(Xj)
                        T = list(set(Neigborhood_fi_List) & set(Neigborhood_fj_List))
                        Temp = float(
                            Neigborhood_fi_List.__len__() * Neigborhood_fj_List.__len__() / (DataLength * T.__len__()))
                        Mid += math.log2(Temp)
                    Result = float((-1 / DataLength) * Mid)
                    Redundancuy_Matrix[fi, fj] = Result
        return Redundancuy_Matrix

    # é€‰æ‹©æœ€ä¼˜ç‰¹å¾
    def ChooseTheBestFeature(self, RemainingFeatures, selecedFeatures, LabelList, RelevanceMatrix,
                             RedundancyMatrix, NeighborhoodMatrix_Feature, Threshold):
        Length_SelectedFeatures = len(selecedFeatures)
        if Length_SelectedFeatures == 0:
            # åˆå§‹é˜¶æ®µï¼Œç›´æ¥æŒ‰ç›¸å…³æ€§æœ€å¤§é€‰æ‹©
            Temp_List = []
            for row in RemainingFeatures:
                T = sum(RelevanceMatrix[row, :])
                Temp_List.append(T)
            Result = RemainingFeatures[Temp_List.index(max(Temp_List))]
            Score = max(Temp_List)  # è®°å½•è¯¥ç‰¹å¾çš„å¾—åˆ†
            return Result, Score
        else:
            # æœ‰å·²é€‰ç‰¹å¾æ—¶ï¼Œç»¼åˆè€ƒè™‘ç›¸å…³æ€§ã€å†—ä½™æ€§ã€äº¤äº’æ€§
            Result_List = []
            for f in RemainingFeatures:
                Relevance_Value = sum(RelevanceMatrix[f, :])
                T2 = 0
                for s in selecedFeatures:
                    if RedundancyMatrix[f, s] == 0:
                        T2 += RedundancyMatrix[s, f]
                    else:
                        T2 += RedundancyMatrix[f, s]
                Redundancy_Value = T2
                Interactive_Value = self.ComputeInteractiveBetween_fi_and_S(f, selecedFeatures, LabelList,
                                                                            RelevanceMatrix, RedundancyMatrix,
                                                                            NeighborhoodMatrix_Feature, Threshold)
                # è®¡ç®—å½“å‰ç‰¹å¾çš„è¯„åˆ†
                Score = Relevance_Value - Redundancy_Value / len(selecedFeatures) + Interactive_Value
                # æ¯ä¸ªç‰¹å¾çš„é‡è¦åº¦ç”±ä»¥ä¸‹ä¸‰éƒ¨åˆ†å†³å®šï¼š
                # ç›¸å…³æ€§ (Relevance_Value)ï¼šç‰¹å¾ä¸ç›®æ ‡åˆ—çš„å…³ç³»ï¼Œè¶Šé«˜è¶Šé‡è¦ã€‚
                # å†—ä½™æ€§ (Redundancy_Value)ï¼šç‰¹å¾ä¸å·²é€‰ç‰¹å¾çš„é‡å¤ç¨‹åº¦ï¼Œè¶Šä½è¶Šé‡è¦ã€‚
                # äº¤äº’æ€§ (Interactive_Value)ï¼šç‰¹å¾ä¸å·²é€‰ç‰¹å¾çš„ååŒä½œç”¨ï¼Œè¶Šé«˜è¶Šé‡è¦ã€‚
                Result_List.append(Score)
            # æ‰¾åˆ°å¾—åˆ†æœ€é«˜çš„ç‰¹å¾
            Best_Index = Result_List.index(max(Result_List))
            Result = RemainingFeatures[Best_Index]
            Score = Result_List[Best_Index]
            return Result, Score



    def FeatureSelectionMarkerEnhancement(self, label, weight_factor):
        self.target_column = label
        self.label_length = len(label)
        all_length = len(self.get_columns())
        # ç›®æ ‡åˆ—
        LabelIndexList = [i for i in range(all_length - self.label_length, all_length)]
        # æ ‡è®°å¢å¼º 0~1
        self.labellist = self.ConstructLiInstanceList(LabelIndexList, weight_factor)

    # åŸå§‹ç‰¹å¾é›†åˆæŒ‰é‡è¦åº¦æ’åº
    def RankFeaturesBasedOnLabelDistributionUsingNeigborhoodMutualInformation(self, omega):
        all_length = len(self.get_columns())
        # ç‰¹å¾åˆ—
        ConditionalAttributes = [i for i in range(all_length - self.label_length)]
        # ç›®æ ‡åˆ—
        LabelIndexList = [i for i in range(all_length - self.label_length, all_length)]
        # è·å–æ ‡è®°æƒé‡
        Label_Weigth_List = self.Get_Label_Weight(self.label_length, omega)
        # è·å–é¢†åŸŸé˜ˆå€¼
        Threshold = self.GetNeigborhoodThreshold(ConditionalAttributes, omega)
        # æ¯ä¸ªå®ä¾‹ä¸‹çš„é¢†åŸŸé›†åˆçš„çŸ©é˜µ
        NeighborhoodMatrix_Attri = self.ConstructNeighborhoodMatrix_Feature(ConditionalAttributes, Threshold)
        # æ„å»ºä¾èµ–çŸ©é˜µ
        RelevanceMatrix = self.ConstructRelevanceMatrix(ConditionalAttributes, LabelIndexList, Label_Weigth_List,
                                                        NeighborhoodMatrix_Attri, self.labellist, Threshold)
        # æ„å»ºå†—ä½™çŸ©é˜µ
        RedundancyMatrix = self.ConstructRedundancyMatrix(ConditionalAttributes, NeighborhoodMatrix_Attri,
                                                          Threshold)
        Selected_Features = []
        Feature_Importance = {}  # ç”¨äºå­˜å‚¨ç‰¹å¾çš„é‡è¦åº¦
        Judge_Criterion = len(ConditionalAttributes)

        while len(Selected_Features) < Judge_Criterion:
            # æŒ‘é€‰å‡ºæœ€ä¼˜è§£å’Œå¯¹åº”çš„é‡è¦åº¦
            The_Best_Feature, Score = self.ChooseTheBestFeature(ConditionalAttributes, Selected_Features,
                                                                LabelIndexList,
                                                                RelevanceMatrix, RedundancyMatrix,
                                                                NeighborhoodMatrix_Attri,
                                                                Threshold)
            Selected_Features.append(The_Best_Feature)
            Feature_Importance[The_Best_Feature] = float(Score)  # è®°å½•ç‰¹å¾åŠå…¶é‡è¦åº¦
            ConditionalAttributes.remove(The_Best_Feature)

        # è¿”å›é€‰æ‹©çš„ç‰¹å¾ä»¥åŠå¯¹åº”çš„é‡è¦åº¦
        return Feature_Importance


if __name__ == '__main__':
    file_path = '1.csv'
    feature_selection = FeatureSelectionAlgorithm(file_path=file_path)
    feature_selection.loadfile()
    response = ['d1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7']
    all_columns = feature_selection.get_columns()
    feature_selection.exchange(response)
    feature_selection.normalization()

    parameter_omega = 0.66
    label_length = len(response)
    feature_selection.FeatureSelectionMarkerEnhancement(response)
    list2 = feature_selection.RankFeaturesBasedOnLabelDistributionUsingNeigborhoodMutualInformation(parameter_omega)
    print(list2)


# è¿™ä¸ªä»£ç å®ç°äº†ä¸€ä¸ªç‰¹å¾é€‰æ‹©ç®—æ³•çš„æ¡†æ¶ï¼Œåˆ©ç”¨é‚»åŸŸè®¡ç®—å’Œæ ‡è®°æƒé‡æ¥è¯„ä¼°ç‰¹å¾çš„é‡è¦æ€§ï¼Œå¹¶åŸºäºå†—ä½™å’Œç›¸å…³æ€§æ¥è¿›è¡Œç‰¹å¾ç­›é€‰ã€‚ç‰¹å¾é€‰æ‹©ç®—æ³•ä¸­çš„å¤§éƒ¨åˆ†åŠŸèƒ½ä¸»è¦é›†ä¸­åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š
